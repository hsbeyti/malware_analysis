# Import necessary libraries
from IPython import get_ipython
from IPython.display import display
# %% [markdown]
# # Malware Analysis based on sys Calls Pattern
# %% [markdown]
# # File Data Structure
# %% [markdown]
# ## Header Format:
# API name, API ID, present(0/1), percentage(real), pattern(1),pattern (2),pattern (3)......, pattern(20)
# 
# **Total number of APIs = 401**
# 
# Each Malware/Goodware set of APIs is terminated by a separator line:
# 
# ,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,#,
# 
# Total number of samples:
# 422 benign
# 
# *   Listeneintrag
# *   Listeneintrag
# 
# All malware are dlimetd by:
# 
# 1,1,1,1,1,1,1,1,1,1
# 
# 374 malware
# Labeling is based on the order of appearance in the file
# 
# The first 422 samples are benign
# 
# *   Listeneintrag
# *   Listeneintrag
# 
# 
# The last 374 samples are malware
# %% [markdown]
# # Loading CSV File
# %%
# Import necessary libraries for data processing and visualization
import pandas as pd
import pylab as pl
import numpy as np
import scipy.optimize as opt
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
%matplotlib inline 
import matplotlib.pyplot as plt
# %%
# Mount Google Drive to access the data file
from google.colab import drive
drive.mount('/content/gdrive')
# %% [markdown]
# 
# %%

# %%
# Define constants for the number of benign and malicious samples, and the number of APIs
BENIGN = 463
MALICIOUS = 582
APIS = 401
# %%
# Define the path to the CSV file containing the malware data
file ="gdrive/MyDrive/malware_data/readyForMLF.csv"
# Import libraries for file handling, numerical operations, and plotting
import csv
import numpy as np
import matplotlib.pyplot as plt
#import seaborn as sns

# Initialize a matrix to store the malware-syscall data
M = np.zeros((BENIGN+MALICIOUS,APIS)) # malware - syscall matrix
# Initialize lists to store syscall names and their corresponding numbers
syscalls = []
syscalls_nm = []
# %%
# Open and read the CSV file
with open(file) as csv_file:
    # Create a CSV reader object
    csv_reader = csv.reader(csv_file, delimiter=',')
    # Initialize counters for lines and files
    line_count = 0
    file_count = 0
    # Set initial label to 'benign'
    label = 'benign'
    # Iterate through each row in the CSV file
    for row in csv_reader:
        # Check for separator line
        if row[0]=="#": #separator
           file_count+=1
           continue
        # Check for malware label
        if row[0]=="1":
            label = 'MALICIOUS'
            continue
        # try:
        # Extract syscall number and file number
        syscallNb = int(row[1])
        fileNb = file_count
        # Initialize variables for pattern length calculation
        avgPatt=0
        max=0
        # Store syscall names and numbers if it's the first file
        if file_count == 0:
          syscalls.append(row[0])
          syscalls_nm.append(row[1])
          line_count+=1
        # Check if syscall is present
        if  int(row[2])==1: # syscall is present
          #API name, API ID, present(0/1), percentage(real), pattern(1),pattern (2),pattern (3)......, pattern(20)
          # Avg Pattern length computation
          # Calculate average pattern length
          for xx in range(4, 23):
                avgPatt+=int(row[xx])
          # Store average pattern length in the matrix
          M[fileNb][syscallNb] = avgPatt
        # If syscall is not present, store 0 in the matrix
        else:
            M[fileNb][syscallNb] = 0
       # if  syscallNb == (APIS-1):
          #   M[fileNb][APIS] = label
            # print(label)
        # except Exception:
        #     print("something wrong with the file!")

# %%
# Print the number of syscalls
print(len(syscalls))
# %%

# %%

# %%
# Identify and remove columns with all 0 values (unused APIs)
idx = np.argwhere( np.all(M == 0, axis=0) )
print (len(idx), "/", M.shape[1], "columns are all 0")

M2 = np.delete(M, idx, axis=1)

# Update the number of APIs after removing unused ones
APIS_C = M2.shape[1]
print (M2.shape)
# %%
# Print the number of files processed
print(f'Processed {file_count} files.')
# %%
# Clean the list of syscalls by removing unused ones
usedSysCalls = [ syscalls[x] for x in range(APIS) if not x in idx ]
len(usedSysCalls)
print(usedSysCalls)
# %%
# Clean the list of syscall numbers by removing unused ones
usedSysCalls_nm = [ syscalls_nm[x] for x in range(APIS) if not x in idx ]
print(len(usedSysCalls_nm))
print(usedSysCalls_nm)
# %%
# Visualization heatmaps using seaborn

# libraries
import seaborn as sns
import pandas as pd

# Create a pandas DataFrame from the malware-syscall matrix
df = pd.DataFrame(M2, index=[str(x) for x in range(M2.shape[0])], columns=usedSysCalls)
# Create labels for benign and malicious samples
labels = [0 for x in range(BENIGN)] + [ 1 for x in range(MALICIOUS)]
# Add a 'class' column to the DataFrame to store the labels
df['class'] = labels
# %%
# Display descriptive statistics of the DataFrame
df.describe()
# %%
# Convert the DataFrame to integer data types
df_int = df.convert_dtypes(convert_integer=True)
# %%

# Create a scatter plot of 'class' vs 'NtWriteFile'
xx = df["class"]
yy = df["NtWriteFile"]
plt.scatter(xx,yy)
plt.xlabel("class")
plt.ylabel("Nt write")
# %%
# Count the occurrences of each class
class_count = df["class"].value_counts()
print(class_count)
# %%
# Create a boxenplot of 'NtWriteFile'
sns.boxenplot(x="NtWriteFile", data=df)
# %%
# Display the data types of each column in the DataFrame
df_int.dtypes
# %%
# Assign the integer DataFrame to a new variable
class_df = df_int
# %%

# %%
# Create a DataFrame containing only the features (excluding 'class')
df_int_feature  = df_int.drop(['class'], axis=1)
df_int_feature.head()
# %%
# Display the first few rows of the class DataFrame
class_df.head()
# %%
# Extract the class labels as a NumPy array
y = np.asarray( df_int['class'])

# Convert the class labels to integers
y=y.astype('int')
y [0:600]
# %%
# Extract the features as a NumPy array
X = np.asarray(df_int_feature)
# Convert the features to integers
X=X.astype('int')
X[0:5]
# %%
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.7, random_state=10)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)
y_train[1:80]
# %%
# Import the SVM classifier from scikit-learn
from sklearn import svm
# Create an SVM classifier with an RBF kernel
clf = svm.SVC(kernel='rbf')
# Train the classifier on the training data
clf.fit(X_train, y_train)
# %%
# Predict the classes of the test data
yhat = clf.predict(X_test)
yhat [0:50]
# %%
# Display the first few elements of the true class labels for the test data
y_test[0:5]
# %%
# Import the f1_score metric from scikit-learn
from sklearn.metrics import f1_score
# Calculate the weighted F1 score
f1_score(y_test, yhat, average='weighted')
# %%
# Import functions for generating classification reports and confusion matrices
from sklearn.metrics import classification_report, confusion_matrix
import itertools
# %%
# Define a function to plot the confusion matrix
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
# %%
# Compute the confusion matrix
cnf_matrix = confusion_matrix(y_test, yhat, labels=[0,1])
np.set_printoptions(precision=2)

# Print the classification report
print (classification_report(y_test, yhat))

# Plot the non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=['Benign(0)','Malignant(1)'],normalize= False,  title='Confusion matrix')
# %% [markdown]
# # Test loading CSv from Google Drive
# %% [markdown]
#